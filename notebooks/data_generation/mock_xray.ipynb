{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2a80ca3",
   "metadata": {},
   "source": [
    "## mock_xray.ipynb\n",
    "\n",
    "This file is used to generate X-ray mock images of TNG-Cluster primary zoom-in targets at snapshot 84.  \n",
    "The codes are modified from example scripts provided in the TNG Lab.\n",
    "\n",
    "Thanks to John ZuHone for preparing the original walkthrough for the LEM workshop in February 2022, and to Dylan Nelson for opening the TNG Lab resources to us.\n",
    "\n",
    "**Input Requirements**\n",
    "\n",
    "Local access to:\n",
    "- Snapshot cutouts of TNG-Cluster primary zoom-in targets  \n",
    "- CSV files listing TNG-Cluster primary zoom-in targets traced back to snapshot 84 from snapshot 89  \n",
    "\n",
    "All source files are organized under the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede33a5-e992-45a7-8f37-9641d5b65224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Packages\n",
    "import numpy as np\n",
    "import h5py\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress, pearsonr, spearmanr\n",
    "import seaborn as sns\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.stats as stats\n",
    "# Physics-related Packages\n",
    "from astropy.cosmology import Planck15 as cosmo\n",
    "import astropy.units as u\n",
    "from astropy.constants import M_sun\n",
    "import ast\n",
    "\n",
    "# extra pack for X-ray mocking\n",
    "from regions import RectangleSkyRegion\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "from astropy import wcs\n",
    "from astropy.io import fits\n",
    "import yt\n",
    "import pyxsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67bd547-b4c3-4699-a51c-446281d5e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get GroupPos and GroupR\n",
    "# read CSV\n",
    "cat_df = pd.read_csv('fof_halo_to_sub84.csv')\n",
    "\n",
    "cat_df['GroupPos'] = cat_df['GroupPos'].apply(ast.literal_eval)\n",
    "\n",
    "FOF_Halo_IDs = cat_df['FOF_Halo_ID_At84']\n",
    "GroupPos = cat_df['GroupPos']\n",
    "Group_R_Crit500 = cat_df['Group_R_Crit500']\n",
    "SubhaloIDs = cat_df['Subhalo_ID_At84']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e7d030-8385-4e47-8123-9a67eb41f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from soxs.utils import soxs_cfg\n",
    "soxs_cfg.set(\"soxs\", \"bkgnd_nH\", \"0.018\") # avoid configparser error by specifying here\n",
    "import soxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf298c4-4905-44cc-bed6-8b16ee7648df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sim info\n",
    "import requests\n",
    "import time\n",
    "\n",
    "headers = {\"api-key\": \"API KEY\"}\n",
    "\n",
    "\n",
    "# get sim info\n",
    "snapshot = 84\n",
    "sim_url = \"http://www.tng-project.org/api/TNG-Cluster/\"\n",
    "snap_url = f\"http://www.tng-project.org/api/TNG-Cluster/snapshots/{snapshot}/\"\n",
    "\n",
    "r = requests.get(sim_url, headers=headers)\n",
    "sim_info = r.json()\n",
    "\n",
    "snap = requests.get(snap_url, headers=headers)\n",
    "snap_info = snap.json()\n",
    "\n",
    "redshift = snap_info['redshift']\n",
    "factor_a = 1/(1+redshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6942af6-2bb8-4aea-89fb-ae439bc21d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_file(halo_index):\n",
    "    # get halo info\n",
    "    halo_id = int(FOF_Halo_IDs[halo_index])\n",
    "    subhalo_id = int(SubhaloIDs[halo_index])\n",
    "    #group_r = Group_R_Crit500[halo_index]\n",
    "\n",
    "    halo = {\n",
    "    \"GroupPos\": GroupPos[FOF_Halo_IDs==halo_id].iloc[0]\n",
    "    }\n",
    "\n",
    "    # generate header\n",
    "    header = {\n",
    "    \"BoxSize\": float(sim_info[\"boxsize\"]),                 # [ckpc/h]\n",
    "    \"Time\": factor_a,                                            # z = redshift çš„ cosmic time\n",
    "    \"Redshift\": redshift,\n",
    "    \"Omega0\": float(sim_info[\"omega_0\"]),                  # Omega matter\n",
    "    \"OmegaLambda\": float(sim_info[\"omega_L\"]),             # Omega Lambda\n",
    "    \"HubbleParam\": float(sim_info[\"hubble\"]),              # Hubble parameter\n",
    "    }\n",
    "\n",
    "    # 1 ckpc/h in cm (comoving kiloparsec per h) actually kpc in cm when simulation flag is turned on\n",
    "    unit_length_cm = 1*(u.kpc).to(u.cm)\n",
    "    \n",
    "    # 1e10 Msun/h in grams actually 10^10M_sun in cm when simulation flag is turned on\n",
    "    unit_mass_g = (1e10 * M_sun).to(u.g).value\n",
    "    \n",
    "    # 1 km/s to cm/s\n",
    "    unit_velocity_cms = (1 * u.km / u.s).to(u.cm / u.s).value\n",
    "    \n",
    "    header_snap = {\n",
    "        \"UnitLength_in_cm\": unit_length_cm,\n",
    "        \"UnitMass_in_g\": unit_mass_g,\n",
    "        \"UnitVelocity_in_cm_per_s\": unit_velocity_cms\n",
    "    }\n",
    "    \n",
    "    # create mass table, only dm mass needed\n",
    "    mass_table = np.zeros(6, dtype=np.float64)\n",
    "    mass_table[1] = float(sim_info[\"mass_dm\"])  # PartType1 = DM\n",
    "    \n",
    "    # add header snap\n",
    "    header_snap[\"MassTable\"] = mass_table\n",
    "\n",
    "    # combine header and snap content\n",
    "    filename = \"halo_%d.hdf5\" % halo_id\n",
    "    #halo_file_name = f'/home/chuiyang/Illustris/TNGCluster_Cutout/snap84/cutout_sub{subhalo_id}_FOF{halo_id}.hdf5'\n",
    "    halo_file_name = f'/users/ckong13/data/Chuiyang/TNGCluster_Cutout/snap{snapshot}/cutout_sub{subhalo_id}_FOF{halo_id}.hdf5'\n",
    "    \n",
    "    with h5py.File(halo_file_name) as cut_f:\n",
    "        \n",
    "        # print(cut_f['PartType0'].keys())\n",
    "        num_gas = cut_f[\"PartType0/Coordinates\"].shape[0]\n",
    "        with h5py.File(filename,'w') as yt_f:\n",
    "            for key in cut_f['PartType0'].keys():\n",
    "                yt_f[f\"PartType0/{key}\"] = cut_f[f\"PartType0/{key}\"][:] \n",
    "                \n",
    "            # some metadata that yt demands\n",
    "            yt_f.create_group('Header')\n",
    "            yt_f['Header'].attrs['NumFilesPerSnapshot'] = 1\n",
    "            yt_f['Header'].attrs['MassTable'] = header_snap['MassTable']\n",
    "            yt_f['Header'].attrs['BoxSize'] = header['BoxSize']\n",
    "            yt_f['Header'].attrs['Time'] = header['Time']\n",
    "            yt_f['Header'].attrs['Redshift'] = header['Redshift']\n",
    "            yt_f['Header'].attrs['NumPart_ThisFile'] = np.array([num_gas,0,0,0,0,0])\n",
    "            \n",
    "            # Must have the next six for correct units\n",
    "            yt_f[\"Header\"].attrs[\"HubbleParam\"] = header[\"HubbleParam\"]\n",
    "            yt_f[\"Header\"].attrs[\"Omega0\"] = header[\"Omega0\"]\n",
    "            yt_f[\"Header\"].attrs[\"OmegaLambda\"] = header[\"OmegaLambda\"]\n",
    "    \n",
    "            # These correspond to the values from the TNG simulations\n",
    "            yt_f[\"Header\"].attrs[\"UnitLength_in_cm\"] = header_snap['UnitLength_in_cm']\n",
    "            yt_f[\"Header\"].attrs[\"UnitMass_in_g\"] = header_snap['UnitMass_in_g']\n",
    "            yt_f[\"Header\"].attrs[\"UnitVelocity_in_cm_per_s\"] = header_snap['UnitVelocity_in_cm_per_s']\n",
    "\n",
    "    return halo_id, halo_file_name, filename, halo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2920174e-6004-4e57-a8bc-f8aabbdec4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hot gas\n",
    "def hot_gas(pfilter, data):\n",
    "    pfilter1 = data[pfilter.filtered_type, \"temperature\"] > 3.0e5\n",
    "    pfilter2 = data[\"PartType0\", \"StarFormationRate\"] == 0.0\n",
    "    pfilter3 = data[\"PartType0\", \"GFM_CoolingRate\"] < 0.0\n",
    "    return (pfilter1 & pfilter2) & pfilter3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efefd270-8edc-46ac-aaff-e8345abc45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_source_model(emin=0.05, emax=4.0, nbins=8):\n",
    "    \n",
    "    source_model = pyxsim.CIESourceModel(\n",
    "    \"apec\", emin, emax, nbins, (\"hot_gas\", \"metallicity\"),\n",
    "    temperature_field=(\"hot_gas\", \"temperature\"),\n",
    "    emission_measure_field=(\"hot_gas\", \"emission_measure\")\n",
    "    )\n",
    "    \n",
    "    return source_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf51e6a-98d9-4760-921e-aca7ca6a89f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_width_mpc(halo_index):\n",
    "    group_r = Group_R_Crit500[halo_index]\n",
    "    group_r_q = group_r * factor_a * u.kpc / sim_info[\"hubble\"]\n",
    "    width_mpc = 2* group_r_q.to(u.Mpc)\n",
    "\n",
    "    return float(width_mpc.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dddc69-f466-4ac4-99d6-6458cd835bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile = \"xray_chandra.log\"\n",
    "logging.basicConfig(\n",
    "    level    = logging.INFO, \n",
    "    format   = \"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt  = \"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers = [\n",
    "        logging.FileHandler(logfile, mode=\"w\"), \n",
    "        # logging.StreamHandler()               \n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "logger.info(\"===== Start X-ray Mock=====\")\n",
    "start_all = time.time()\n",
    "\n",
    "# define source parameter\n",
    "exp_time = (2000., \"ks\") # exposure time\n",
    "area = (600, \"cm**2\") # collecting area\n",
    "redshift = snap_info['redshift']\n",
    "# define instrument\n",
    "instrument = \"chandra_acisi_cy22\"\n",
    "ins_exp_time = (2000., \"ks\")\n",
    "\n",
    "for halo_index in range(len(cat_df)):\n",
    "# for halo_index in range(259,260):\n",
    "    logger.info(f\"--- start halo index {halo_index} ---\")\n",
    "    \n",
    "    halo_id, halo_file_name, filename, halo = generate_input_file(halo_index)\n",
    "\n",
    "    logger.info(f\"  generate_input_file -> {filename}\")\n",
    "    \n",
    "    ds = yt.load(filename)\n",
    "    yt.add_particle_filter(\"hot_gas\", function=hot_gas,\n",
    "                           filtered_type='gas', requires=[\"temperature\",\"density\"])\n",
    "    ds.add_particle_filter(\"hot_gas\")\n",
    "    \n",
    "    # source model\n",
    "    source_model = generate_source_model(emin=0.05, emax=4.0, nbins=8)\n",
    "    \n",
    "    # get width\n",
    "    c = ds.arr([halo[\"GroupPos\"][0], halo[\"GroupPos\"][1], halo[\"GroupPos\"][2]], \"code_length\")\n",
    "    width = ds.quan(get_width_mpc(halo_index), \"Mpc\")\n",
    "    le = c - 0.5*width\n",
    "    re = c + 0.5*width\n",
    "    #le = c - width\n",
    "    #re = c + width\n",
    "    box = ds.box(le, re)\n",
    "\n",
    "    # generate photon and events\n",
    "    n_photons, n_cells = pyxsim.make_photons(f\"halo_{halo_id}_photons\", box, redshift, area, exp_time, source_model)\n",
    "    logger.info(\"make_photons: photons, cells\")\n",
    "    \n",
    "    n_events = pyxsim.project_photons(f\"halo_{halo_id}_photons\", f\"halo_{halo_id}_events\", \"x\", (0.,0.),\n",
    "                                      absorb_model=\"wabs\", nH=0.01)\n",
    "    logger.info(\"project_photons -> events\")\n",
    "    \n",
    "    events = pyxsim.EventList(f\"halo_{halo_id}_events.h5\")\n",
    "    events.write_to_simput(f\"halo_{halo_id}\", overwrite=True)\n",
    "\n",
    "    # mock obs\n",
    "    instrument = \"chandra_acisi_cy22\"\n",
    "    soxs.instrument_simulator(f\"halo_{halo_id}_simput.fits\", f\"halo_{halo_id}_evt.fits\", ins_exp_time, instrument, (0.,0.), overwrite=True, foreground=False, ptsrc_bkgnd=False)\n",
    "\n",
    "    # exposure calibration file\n",
    "    exp_file  = f\"halo_{halo_id}_expmap.fits\"  \n",
    "    soxs.make_exposure_map(f\"halo_{halo_id}_evt.fits\",\n",
    "                       exp_file,\n",
    "                       energy = 1.2,\n",
    "                       overwrite=True)\n",
    "    \n",
    "    # plot\n",
    "    soxs.write_image(f\"halo_{halo_id}_evt.fits\", f\"halo_{halo_id}_img.fits\", emin=0.1, emax=2.0, overwrite=True, expmap_file = exp_file)\n",
    "    logger.info(\"finish write_image\")    \n",
    "\n",
    "    # 1) delete yt dataset\n",
    "    ds = None\n",
    "\n",
    "    # 2) delete biproductor\n",
    "    try:\n",
    "        del n_photons, events\n",
    "    except NameError:\n",
    "        pass\n",
    "\n",
    "    # 3) delete local variables\n",
    "    for var in [\"box\",\"c\",\"width\",\"le\",\"re\",\"source_model\"]:\n",
    "        if var in locals():\n",
    "            del locals()[var]\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Illustris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
