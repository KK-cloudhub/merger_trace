{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2166c2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import logging\n",
    "import shutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Physics-related Packages\n",
    "from astropy.cosmology import Planck15\n",
    "# Physics-related Packages\n",
    "from astropy.cosmology import Planck15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70141c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapnum = 84\n",
    "FilePath = f\"/users_path/merger_trace/data/tng_cluster/tng_cluster_groupcat/groupcat_0{snapnum}/\"\n",
    "SavePath = f\"/users_path/merger_trace/data/tng_cluster/tng_cluster_targetcat/targethalo_cat_0{snapnum}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecafa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparations for read box info from the url\n",
    "import requests\n",
    "\n",
    "baseUrl = 'http://www.tng-project.org/api/'\n",
    "headers = {\"api-key\":\"API KEY\"}\n",
    "\n",
    "def get(path, params=None):\n",
    "    # make HTTP GET request to path\n",
    "    r = requests.get(path, params=params, headers=headers)\n",
    "\n",
    "    # raise exception if response code is not HTTP SUCCESS (200)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    if r.headers['content-type'] == 'application/json':\n",
    "        return r.json() # parse json responses automatically\n",
    "\n",
    "    if 'content-disposition' in r.headers:\n",
    "        filename = r.headers['content-disposition'].split(\"filename=\")[1]\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        return filename # return the filename string\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7be030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue a request to the API root\n",
    "r = get(baseUrl)\n",
    "\n",
    "# Print out all the simulation names\n",
    "names = [sim['name'] for sim in r['simulations']]\n",
    "# Get the index of TNG300-1\n",
    "i = names.index('TNG-Cluster')\n",
    "# Get the info of simulation Illustris-3\n",
    "sim = get( r['simulations'][i]['url'] )\n",
    "sim.keys()\n",
    "\n",
    "# get the snaps info this simulation\n",
    "snaps = get(sim['snapshots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411bfef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim Box parameters\n",
    "Snap_Index = snapnum # the snapshots index in the total 100 snapshots taking at different z\n",
    "BoxSize = sim['boxsize'] # unit: ckpc/h\n",
    "Redshift = snaps[Snap_Index]['redshift'] # current redshift of our current snap\n",
    "\n",
    "# Short description of cosmological parameters Planck2015\n",
    "h_atz = Planck15.H(Redshift).value/100 # unit 100km/[s*Mpc]\n",
    "\n",
    "# h should be h_0, but it does not make a difference, so I don't change the codes here\n",
    "LowerMass_lim = 10**3 * h_atz # units 10^ 10 ð‘€âŠ™/h\n",
    "HigherMass_lim = 10**10 * h_atz # units 10^ 10 ð‘€âŠ™/h\n",
    "\n",
    "print(h_atz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0123c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure file paths and log file\n",
    "log_file_path = \"file_check_log.txt\"# Basic Package s\n",
    "\n",
    "chunk_numbers = range(0, 600)  # Assume chunk_number ranges from 0 to 599\n",
    "\n",
    "# Open the log file for writing\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    log_file.write(\"File Check Log\\n\")\n",
    "    log_file.write(\"================\\n\")\n",
    "\n",
    "    # Iterate through all chunk_numbers\n",
    "    for chunk_number in chunk_numbers:\n",
    "        file_name = FilePath + f'fof_subhalo_tab_0{snapnum}.{chunk_number}.hdf5'\n",
    "\n",
    "        # Check if the file exists\n",
    "        if os.path.isfile(file_name):\n",
    "            try:\n",
    "                # Try opening the HDF5 file to check if it is readable\n",
    "                with h5py.File(file_name, \"r\") as hdf_file:\n",
    "                    log_file.write(f\"{file_name}: File exists and is a valid HDF5 file.\\n\")\n",
    "            except Exception as e:\n",
    "                log_file.write(f\"{file_name}: File exists but is not a valid HDF5 file. Error: {e}\\n\")\n",
    "        else:\n",
    "            log_file.write(f\"{file_name}: File does not exist.\\n\")\n",
    "\n",
    "print(f\"File check completed. Results are saved in {log_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c29f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Delete the Previous File in the Directory\n",
    "\n",
    "directory = SavePath\n",
    "\n",
    "if os.path.exists(directory):\n",
    "    # loop over all files/directories in the target directory\n",
    "    for file_or_dir in os.listdir(directory):\n",
    "        file_or_dir_path = os.path.join(directory, file_or_dir)\n",
    "        try:\n",
    "            if os.path.isfile(file_or_dir_path) or os.path.islink(file_or_dir_path):\n",
    "                os.remove(file_or_dir_path)  \n",
    "                print(f\"{file_or_dir_path} has already been deleted\")\n",
    "            elif os.path.isdir(file_or_dir_path):\n",
    "                shutil.rmtree(file_or_dir_path)  \n",
    "                print(f\"{file_or_dir_path} has already been deleted\")\n",
    "        except Exception as e:\n",
    "            print(f\"cannot remove {file_or_dir_path}: {e}\")\n",
    "else:\n",
    "    print(f\"The directory {directory} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171fedc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the null files for sky zones\n",
    "# Dict names used here are similar to those in Illustris\n",
    "\n",
    "Target_Halo_Catalog = f'{SavePath}TargetHalo_MergerCat_0{snapnum}.hdf5'\n",
    "\n",
    "with h5py.File(Target_Halo_Catalog, 'w') as hdf:\n",
    "    # create dict for fof halos\n",
    "    Group = hdf.create_group('Group')\n",
    "\n",
    "    Group.create_dataset(\n",
    "        'GroupCM',\n",
    "        shape = (0,3),\n",
    "        maxshape = (None,3),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: ckpc/h, Dims: (N,3)\n",
    "    \n",
    "    Group.create_dataset(\n",
    "        'GroupFirstSub',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: None, Dims: (N,)\n",
    "    \n",
    "    Group.create_dataset(\n",
    "        'GroupLenType',\n",
    "        shape = (0,6),\n",
    "        maxshape = (None,6),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: None, Dims: (N,6)\n",
    "    \n",
    "    Group.create_dataset(\n",
    "        'GroupMassType',\n",
    "        shape = (0,6),\n",
    "        maxshape = (None,6),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: 10^10 M_{sun}/h, Dims: (N,6)\n",
    "    \n",
    "    Group.create_dataset(\n",
    "        'GroupNsubs',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: None, Dims: (N,)\n",
    "    \n",
    "    Group.create_dataset(\n",
    "        'GroupPos',\n",
    "        shape = (0,3),\n",
    "        maxshape = (None,3),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: ckpc/h, Dims: (N,3)\n",
    "    \n",
    "    Group.create_dataset(\n",
    "        'GroupSFR',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: M_{sun}/yr, Dims: (N,)\n",
    "    \n",
    "    Group.create_dataset(\n",
    "        'Group_M_Crit200',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: 10^10 M_{sun}/h, Dims: (N,)\n",
    "    \n",
    "    Group.create_dataset(\n",
    "        'Group_M_Crit500',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: 10^10 M_{sun}/h, Dims: (N,)\n",
    "    \n",
    "    Group.create_dataset(\n",
    "        'Group_M_Mean200',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: 10^10 M_{sun}/h, Dims: (N,)\n",
    "    \n",
    "    Group.create_dataset(\n",
    "        'Group_R_Crit200',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: ckpc/h, Dims: (N,)\n",
    "    \n",
    "    Group.create_dataset(\n",
    "        'Group_R_Crit500',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: ckpc/h, Dims: (N,)\n",
    "    \n",
    "    Group.create_dataset(\n",
    "        'Group_R_Mean200',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: ckpc/h, Dims: (N,)\n",
    "    \n",
    "    Group.create_dataset(\n",
    "        'FOF_Halo_IDs',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: None, Dims: (N,)\n",
    "    \n",
    "    # create dict for subhalos\n",
    "    Subhalo = hdf.create_group('Subhalo')\n",
    "    \n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloFlag',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: None, Dims: (N,)\n",
    "    \n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloCM',\n",
    "        shape = (0,3),\n",
    "        maxshape = (None,3),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: ckpc/h, Dims: (N,3)\n",
    "    \n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloGrNr',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: None, Dims: (N,)\n",
    "    \n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloHalfmassRad',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: ckpc/h, Dims: (N,)\n",
    "    \n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloLenType',\n",
    "        shape = (0,6),\n",
    "        maxshape = (None,6),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: None, Dims: (N,6)\n",
    "    \n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloMassInRadType',\n",
    "        shape = (0,6),\n",
    "        maxshape = (None,6),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: 10^10 M_{sun}/h, Dims: (N,6)\n",
    "    \n",
    "\n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloMassInRad',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: 10^10 M_{sun}/h, Dims: (N,)\n",
    "    \n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloMass',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: 10^10 M_{sun}/h, Dims: (N,)\n",
    "\n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloMassInHalfRad',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: 10^10 M_{sun}/h, Dims: (N,)\n",
    "    \n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloMassType',\n",
    "        shape = (0,6),\n",
    "        maxshape = (None,6),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: 10^10 M_{sun}/h, Dims: (N,6)\n",
    "    \n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloParent',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: None, Dims: (N,)\n",
    "    \n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloPos',\n",
    "        shape = (0,3),\n",
    "        maxshape = (None,3),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: ckpc/h, Dims: (N,3)\n",
    "    \n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloSFR',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: M_{sun}/yr, Dims: (N,)\n",
    "    \n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloSFRinHalfRad',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: M_{sun}/yr, Dims: (N,)\n",
    "\n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloSFRinRad',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: M_{sun}/yr, Dims: (N,)\n",
    "    \n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloVelDisp',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: km/s, Dims: (N,)\n",
    "    \n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloVel',\n",
    "        shape = (0,3),\n",
    "        maxshape = (None,3),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: km/s, Dims: (N,3)\n",
    "    \n",
    "        \n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloSpin',\n",
    "        shape = (0,3),\n",
    "        maxshape = (None,3),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: ckpc/h* km/s, Dims: (N,3)\n",
    "    \n",
    "    Subhalo.create_dataset(\n",
    "        'Subhalo_IDs',\n",
    "        shape = (0,),\n",
    "        maxshape = (None,),\n",
    "        dtype = 'float64'\n",
    "        ) # unit: None, Dims: (N,)\n",
    "    \n",
    "    Subhalo.create_dataset(\n",
    "        'SubhaloStellarPhotometrics',\n",
    "        shape = (0,8),\n",
    "        maxshape = (None,8),\n",
    "        dtype = 'float64'\n",
    "        ) # mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b8128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centersub(Halo_IDs, Sub_GrNr, Sub_Mass):\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds the indices of the top three most massive subhalos for a given halo.\n",
    "\n",
    "    Parameters:\n",
    "    - Halo_ID: Array of halo IDs (single value or array with specific halo ID to match).\n",
    "    - Sub_GrNr: Array indicating the group number (halo) each subhalo belongs to.\n",
    "    - Sub_Mass: Array of subhalo masses.\n",
    "\n",
    "    Returns:\n",
    "    - Numpy array (CenterSub_Index, SecondSub_Index, ThirdSub_Index):\n",
    "      - CenterSub_Index: Index of the most massive subhalo in the halo.\n",
    "      - SecondSub_Index: Index of the second most massive subhalo.\n",
    "      - ThirdSub_Index: Index of the third most massive subhalo.\n",
    "    \"\"\"\n",
    "    CenterSub_Indices = np.zeros(Halo_IDs.shape)\n",
    "    CenterSub_Masses = np.zeros(Halo_IDs.shape)\n",
    "\n",
    "    for i in range(len(Halo_IDs)):\n",
    "        Halo_ID = Halo_IDs[i]\n",
    "        find_Sub = np.where(Sub_GrNr == Halo_ID)[0]\n",
    "        if len(find_Sub)!=0:\n",
    "          find_Sub_Mass = Sub_Mass[find_Sub]\n",
    "          find_Sub_Mass_Sorted = np.argsort(find_Sub_Mass)\n",
    "\n",
    "          CenterSub_Index = np.where(Sub_GrNr == Halo_ID)[0][find_Sub_Mass_Sorted[-1]]\n",
    "          CenterSub_Indices[i] = np.array(CenterSub_Index)\n",
    "          CenterSub_Masses[i] = Sub_Mass[CenterSub_Index]\n",
    "        else:\n",
    "          CenterSub_Indices[i] = -1\n",
    "          CenterSub_Masses[i] = 0\n",
    "    \n",
    "    return CenterSub_Indices, CenterSub_Masses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f1ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort Target Halo Catalog\n",
    "def sort_halos(\n",
    "        snap_number, chunk_number, \n",
    "        FilePath, SavePath,\n",
    "        Last_Halo_IDs, Last_Subhalo_IDs):\n",
    "    '''\n",
    "    Last_Halo_IDs is the number of fof halos in the sorted chunks,\n",
    "    Last_Subhalo_IDs is the number of subhalos in the sorted chunks\n",
    "    '''\n",
    "    groupcat_name = f'{FilePath}fof_subhalo_tab_0{snap_number}.{chunk_number}.hdf5'\n",
    "\n",
    "    with h5py.File(groupcat_name, 'r') as cat_hdf:\n",
    "        if not 'Group/GroupCM' in cat_hdf:\n",
    "            print(f\"Warning: {groupcat_name} is empty. Skipping data reading.\")\n",
    "            num_Halo_thiscat = 0\n",
    "            num_subhalo_thiscat = 0\n",
    "        else:\n",
    "            # get info for groups\n",
    "            GroupCM = cat_hdf['Group/GroupCM'][:]\n",
    "            GroupFirstSub = cat_hdf['Group/GroupFirstSub'][:]\n",
    "            GroupLenType = cat_hdf['Group/GroupLenType'][:]\n",
    "            GroupMassType = cat_hdf['Group/GroupMassType'][:]\n",
    "            GroupNsubs = cat_hdf['Group/GroupNsubs'][:]\n",
    "            GroupPos = cat_hdf['Group/GroupPos'][:]\n",
    "            GroupSFR = cat_hdf['Group/GroupSFR'][:]\n",
    "            Group_M_Crit200 = cat_hdf['Group/Group_M_Crit200'][:]\n",
    "            Group_M_Crit500 = cat_hdf['Group/Group_M_Crit500'][:]\n",
    "            Group_M_Mean200 = cat_hdf['Group/Group_M_Mean200'][:]\n",
    "            Group_R_Crit200 = cat_hdf['Group/Group_R_Crit200'][:]\n",
    "            Group_R_Crit500 = cat_hdf['Group/Group_R_Crit500'][:]\n",
    "            Group_R_Mean200 = cat_hdf['Group/Group_R_Mean200'][:]\n",
    "            FOF_Halo_IDs = np.arange(Last_Halo_IDs, Last_Halo_IDs + GroupNsubs.shape[0])\n",
    "            num_Halo_thiscat = GroupNsubs.shape[0]\n",
    "            print('num_halo_thiscat',num_Halo_thiscat)\n",
    "            \n",
    "            # get info for subhalos\n",
    "            SubhaloFlag = cat_hdf['Subhalo/SubhaloFlag'][:]\n",
    "            SubhaloCM = cat_hdf['Subhalo/SubhaloCM'][:]\n",
    "            SubhaloGrNr = cat_hdf['Subhalo/SubhaloGrNr'][:]\n",
    "            SubhaloHalfmassRad = cat_hdf['Subhalo/SubhaloHalfmassRad'][:]\n",
    "            SubhaloLenType = cat_hdf['Subhalo/SubhaloLenType'][:]\n",
    "            SubhaloMassInRadType = cat_hdf['Subhalo/SubhaloMassInRadType'][:]\n",
    "            SubhaloMassInRad = cat_hdf['Subhalo/SubhaloMassInRad'][:]\n",
    "            SubhaloMassInHalfRad = cat_hdf['Subhalo/SubhaloMassInHalfRad'][:]\n",
    "            SubhaloMass = cat_hdf['Subhalo/SubhaloMass'][:]\n",
    "            SubhaloMassType = cat_hdf['Subhalo/SubhaloMassType'][:]\n",
    "            SubhaloParent = cat_hdf['Subhalo/SubhaloParent'][:]\n",
    "            SubhaloPos = cat_hdf['Subhalo/SubhaloPos'][:]\n",
    "            SubhaloSFR = cat_hdf['Subhalo/SubhaloSFR'][:]\n",
    "            SubhaloSFRinHalfRad = cat_hdf['Subhalo/SubhaloSFRinHalfRad'][:]\n",
    "            SubhaloSFRinRad = cat_hdf['Subhalo/SubhaloSFRinRad'][:]\n",
    "            SubhaloSpin = cat_hdf['Subhalo/SubhaloSpin'][:]\n",
    "            SubhaloVelDisp = cat_hdf['Subhalo/SubhaloVelDisp'][:]\n",
    "            SubhaloVel = cat_hdf['Subhalo/SubhaloVel'][:]\n",
    "            SubhaloStellarPhotometrics = cat_hdf['Subhalo/SubhaloStellarPhotometrics'][:]\n",
    "            Subhalo_IDs = np.arange(Last_Subhalo_IDs, Last_Subhalo_IDs + SubhaloFlag.shape[0])\n",
    "            num_subhalo_thiscat = SubhaloFlag.shape[0]\n",
    "            print('num_subhalo_thiscat',num_subhalo_thiscat)\n",
    "            Centersub_Masses = np.array(get_centersub(FOF_Halo_IDs, SubhaloGrNr, SubhaloMass)[1])\n",
    "    \n",
    "            TargetHalo_inCurrentChunk = np.array(np.where((Centersub_Masses >= LowerMass_lim) & \n",
    "                           (Centersub_Masses <= HigherMass_lim))[0])\n",
    "    \n",
    "            print(TargetHalo_inCurrentChunk)\n",
    "    \n",
    "            TargetCat = f'{SavePath}TargetHalo_MergerCat_0{snapnum}.hdf5'\n",
    "            with h5py.File(TargetCat, 'a') as Target_hdf:\n",
    "    \n",
    "                if TargetHalo_inCurrentChunk.shape[0] > 0:\n",
    "                    \n",
    "                    # resize the original datasets to add data conveniently\n",
    "                    # get the new size\n",
    "                    num_exist_group = Target_hdf['Group/GroupFirstSub'].shape[0]\n",
    "                    num_add_group = TargetHalo_inCurrentChunk.shape[0]\n",
    "                    new_num_group = num_exist_group + num_add_group\n",
    "                    \n",
    "                    # resize\n",
    "                    Target_hdf['Group/GroupCM'].resize((new_num_group,3))\n",
    "                    Target_hdf['Group/GroupFirstSub'].resize((new_num_group,))\n",
    "                    Target_hdf['Group/GroupLenType'].resize((new_num_group,6))\n",
    "                    Target_hdf['Group/GroupMassType'].resize((new_num_group,6))\n",
    "                    Target_hdf['Group/GroupNsubs'].resize((new_num_group,))\n",
    "                    Target_hdf['Group/GroupPos'].resize((new_num_group,3))\n",
    "                    Target_hdf['Group/GroupSFR'].resize((new_num_group,))\n",
    "                    Target_hdf['Group/Group_M_Crit200'].resize((new_num_group,))\n",
    "                    Target_hdf['Group/Group_M_Crit500'].resize((new_num_group,))\n",
    "                    Target_hdf['Group/Group_M_Mean200'].resize((new_num_group,))\n",
    "                    Target_hdf['Group/Group_R_Crit200'].resize((new_num_group,))\n",
    "                    Target_hdf['Group/Group_R_Crit500'].resize((new_num_group,))\n",
    "                    Target_hdf['Group/Group_R_Mean200'].resize((new_num_group,))\n",
    "                    Target_hdf['Group/FOF_Halo_IDs'].resize((new_num_group,))\n",
    "                    # use slices command to add data\n",
    "                    Target_hdf['Group/GroupCM'][num_exist_group:new_num_group,:] = GroupCM[TargetHalo_inCurrentChunk].reshape(-1,3)\n",
    "                    \n",
    "                    Target_hdf['Group/GroupFirstSub'][num_exist_group:new_num_group] = GroupFirstSub[TargetHalo_inCurrentChunk].reshape(-1)\n",
    "                    \n",
    "                    Target_hdf['Group/GroupLenType'][num_exist_group:new_num_group,:] = GroupLenType[TargetHalo_inCurrentChunk].reshape(-1,6)\n",
    "                    \n",
    "                    Target_hdf['Group/GroupMassType'][num_exist_group:new_num_group,:] = GroupMassType[TargetHalo_inCurrentChunk].reshape(-1,6)\n",
    "                    \n",
    "                    Target_hdf['Group/GroupNsubs'][num_exist_group:new_num_group] = GroupNsubs[TargetHalo_inCurrentChunk].reshape(-1)\n",
    "                    \n",
    "                    Target_hdf['Group/GroupPos'][num_exist_group:new_num_group,:] = GroupPos[TargetHalo_inCurrentChunk].reshape(-1,3)\n",
    "                    \n",
    "                    Target_hdf['Group/GroupSFR'][num_exist_group:new_num_group] = GroupSFR[TargetHalo_inCurrentChunk].reshape(-1)\n",
    "                    \n",
    "                    Target_hdf['Group/Group_M_Crit200'][num_exist_group:new_num_group] = Group_M_Crit200[TargetHalo_inCurrentChunk].reshape(-1)\n",
    "                    \n",
    "                    Target_hdf['Group/Group_M_Crit500'][num_exist_group:new_num_group] = Group_M_Crit500[TargetHalo_inCurrentChunk].reshape(-1)\n",
    "                    \n",
    "                    Target_hdf['Group/Group_M_Mean200'][num_exist_group:new_num_group] = Group_M_Mean200[TargetHalo_inCurrentChunk].reshape(-1)\n",
    "                    \n",
    "                    Target_hdf['Group/Group_R_Crit200'][num_exist_group:new_num_group] = Group_R_Crit200[TargetHalo_inCurrentChunk].reshape(-1)\n",
    "                    \n",
    "                    Target_hdf['Group/Group_R_Crit500'][num_exist_group:new_num_group] = Group_R_Crit500[TargetHalo_inCurrentChunk].reshape(-1)\n",
    "                    \n",
    "                    Target_hdf['Group/Group_R_Mean200'][num_exist_group:new_num_group] = Group_R_Mean200[TargetHalo_inCurrentChunk].reshape(-1)\n",
    "                    \n",
    "                    Target_hdf['Group/FOF_Halo_IDs'][num_exist_group:new_num_group] = FOF_Halo_IDs[TargetHalo_inCurrentChunk].reshape(-1)\n",
    "\n",
    "                    del num_exist_group, num_add_group, new_num_group\n",
    "\n",
    "                    print('Finished FOF part')\n",
    "\n",
    "                    # Find Subhalos belong to the target halos\n",
    "                    for FOF_Halo_ID in FOF_Halo_IDs[TargetHalo_inCurrentChunk].reshape(-1):\n",
    "                        find_Sub = np.array(np.where(SubhaloGrNr == FOF_Halo_ID)[0])\n",
    "                        \n",
    "                        print(f\"Processing FOF_Halo_ID: {FOF_Halo_ID}, find_Sub.shape[0]: {find_Sub.shape[0]}\")\n",
    "                        if find_Sub.shape[0]>0:\n",
    "                            num_exist_subhalo = Target_hdf['Subhalo/SubhaloFlag'].shape[0]\n",
    "                            num_add_subhalo = find_Sub.shape[0]\n",
    "                            new_num_subhalo = num_exist_subhalo + num_add_subhalo\n",
    "                            # resize\n",
    "                            Target_hdf['Subhalo/SubhaloFlag'].resize((new_num_subhalo,))\n",
    "                            Target_hdf['Subhalo/SubhaloCM'].resize((new_num_subhalo,3))\n",
    "                            Target_hdf['Subhalo/SubhaloGrNr'].resize((new_num_subhalo,))\n",
    "                            Target_hdf['Subhalo/SubhaloHalfmassRad'].resize((new_num_subhalo,))\n",
    "                            Target_hdf['Subhalo/SubhaloLenType'].resize((new_num_subhalo,6))\n",
    "                            Target_hdf['Subhalo/SubhaloMassInRadType'].resize((new_num_subhalo,6))\n",
    "                            Target_hdf['Subhalo/SubhaloMassInRad'].resize((new_num_subhalo,))\n",
    "                            Target_hdf['Subhalo/SubhaloMassInHalfRad'].resize((new_num_subhalo,))\n",
    "                            Target_hdf['Subhalo/SubhaloMass'].resize((new_num_subhalo,))\n",
    "                            Target_hdf['Subhalo/SubhaloMassType'].resize((new_num_subhalo,6))\n",
    "                            Target_hdf['Subhalo/SubhaloParent'].resize((new_num_subhalo,))\n",
    "                            Target_hdf['Subhalo/SubhaloPos'].resize((new_num_subhalo,3))\n",
    "                            Target_hdf['Subhalo/SubhaloSFR'].resize((new_num_subhalo,))\n",
    "                            Target_hdf['Subhalo/SubhaloSFRinHalfRad'].resize((new_num_subhalo,))\n",
    "                            Target_hdf['Subhalo/SubhaloSFRinRad'].resize((new_num_subhalo,))\n",
    "                            Target_hdf['Subhalo/SubhaloSpin'].resize((new_num_subhalo,3))\n",
    "                            Target_hdf['Subhalo/SubhaloVel'].resize((new_num_subhalo,3))\n",
    "                            Target_hdf['Subhalo/SubhaloVelDisp'].resize((new_num_subhalo,))\n",
    "                            Target_hdf['Subhalo/Subhalo_IDs'].resize((new_num_subhalo,))\n",
    "                            Target_hdf['Subhalo/SubhaloStellarPhotometrics'].resize((new_num_subhalo,8))\n",
    "                            \n",
    "                            #use slices command to add data\n",
    "                            Target_hdf['Subhalo/SubhaloFlag'][num_exist_subhalo:new_num_subhalo] = SubhaloFlag[find_Sub].reshape(-1)\n",
    "                                                                                                \n",
    "                            Target_hdf['Subhalo/SubhaloCM'][num_exist_subhalo:new_num_subhalo,:] = SubhaloCM[find_Sub].reshape(-1,3)\n",
    "                                                                                                \n",
    "                            Target_hdf['Subhalo/SubhaloGrNr'][num_exist_subhalo:new_num_subhalo] = SubhaloGrNr[find_Sub].reshape(-1)\n",
    "                                                                                                \n",
    "                            Target_hdf['Subhalo/SubhaloHalfmassRad'][num_exist_subhalo:new_num_subhalo] = SubhaloHalfmassRad[find_Sub].reshape(-1)\n",
    "                                                                                                \n",
    "                            Target_hdf['Subhalo/SubhaloLenType'][num_exist_subhalo:new_num_subhalo,:] = SubhaloLenType[find_Sub].reshape(-1,6)\n",
    "                                                                                                \n",
    "                            Target_hdf['Subhalo/SubhaloMassInRadType'][num_exist_subhalo:new_num_subhalo,:] = SubhaloMassInRadType[find_Sub].reshape(-1,6)\n",
    "\n",
    "                            Target_hdf['Subhalo/SubhaloMassInRad'][num_exist_subhalo:new_num_subhalo] = SubhaloMassInRad[find_Sub].reshape(-1)\n",
    "\n",
    "                            Target_hdf['Subhalo/SubhaloMassInHalfRad'][num_exist_subhalo:new_num_subhalo] = SubhaloMassInHalfRad[find_Sub].reshape(-1)\n",
    "\n",
    "                            Target_hdf['Subhalo/SubhaloMass'][num_exist_subhalo:new_num_subhalo] = SubhaloMass[find_Sub].reshape(-1)\n",
    "                                                                                                \n",
    "                            Target_hdf['Subhalo/SubhaloMassType'][num_exist_subhalo:new_num_subhalo,:] = SubhaloMassType[find_Sub].reshape(-1,6)\n",
    "                                                                                                \n",
    "                            Target_hdf['Subhalo/SubhaloParent'][num_exist_subhalo:new_num_subhalo] = SubhaloParent[find_Sub].reshape(-1)\n",
    "                                                                                                \n",
    "                            Target_hdf['Subhalo/SubhaloPos'][num_exist_subhalo:new_num_subhalo,:] = SubhaloPos[find_Sub].reshape(-1,3)\n",
    "                                                                                                \n",
    "                            Target_hdf['Subhalo/SubhaloSFR'][num_exist_subhalo:new_num_subhalo] = SubhaloSFR[find_Sub].reshape(-1)\n",
    "\n",
    "                            Target_hdf['Subhalo/SubhaloSFRinHalfRad'][num_exist_subhalo:new_num_subhalo] = SubhaloSFRinHalfRad[find_Sub].reshape(-1)\n",
    "\n",
    "                            Target_hdf['Subhalo/SubhaloSFRinRad'][num_exist_subhalo:new_num_subhalo] = SubhaloSFRinRad[find_Sub].reshape(-1)\n",
    "\n",
    "                            Target_hdf['Subhalo/SubhaloSpin'][num_exist_subhalo:new_num_subhalo,:] = SubhaloSpin[find_Sub].reshape(-1,3)\n",
    "\n",
    "                            Target_hdf['Subhalo/SubhaloVelDisp'][num_exist_subhalo:new_num_subhalo] = SubhaloVelDisp[find_Sub].reshape(-1)\n",
    "\n",
    "                            Target_hdf['Subhalo/SubhaloVel'][num_exist_subhalo:new_num_subhalo] = SubhaloVel[find_Sub].reshape(-1,3)\n",
    "                            \n",
    "                            Target_hdf['Subhalo/SubhaloStellarPhotometrics'][num_exist_subhalo:new_num_subhalo] = SubhaloStellarPhotometrics[find_Sub].reshape(-1,8)\n",
    "                                                                                                \n",
    "                            Target_hdf['Subhalo/Subhalo_IDs'][num_exist_subhalo:new_num_subhalo] = Subhalo_IDs[find_Sub].reshape(-1)\n",
    "                            print('write subhalo info')\n",
    "                                                                                            \n",
    "                        del num_exist_subhalo, num_add_subhalo, new_num_subhalo\n",
    "            \n",
    "            del (GroupCM, GroupFirstSub, GroupLenType, GroupMassType,\n",
    "            GroupNsubs, GroupPos, GroupSFR, Group_M_Crit200, Group_M_Crit500, \n",
    "            Group_M_Mean200, Group_R_Crit200, Group_R_Crit500, Group_R_Mean200,\n",
    "            FOF_Halo_IDs, SubhaloFlag, SubhaloCM, SubhaloGrNr, SubhaloHalfmassRad,\n",
    "            SubhaloLenType, SubhaloMassInRadType, SubhaloMassType, SubhaloParent,\n",
    "            SubhaloPos, SubhaloSFR, Subhalo_IDs, SubhaloMassInRad, SubhaloSFRinHalfRad,\n",
    "            SubhaloSFRinRad, SubhaloSpin, SubhaloVelDisp\n",
    "            )\n",
    "        \n",
    "    gc.collect()\n",
    "    print(f\"Returning from sort_halos: num_Halo_thiscat={num_Halo_thiscat}, num_subhalo_thiscat={num_subhalo_thiscat}\")\n",
    "    return num_Halo_thiscat, num_subhalo_thiscat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5fe942",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f'{FilePath}fof_subhalo_tab_0{snapnum}.0.hdf5', 'r') as cat_hdf:\n",
    "    if 'Subhalo/SubhaloMassInRad' in cat_hdf:\n",
    "        SubhaloSpin = cat_hdf['Subhalo/SubhaloSpin'][:]\n",
    "        print(SubhaloSpin)\n",
    "    else:\n",
    "        print(\"Warning: SubhaloMassInRad dataset is missing!\")\n",
    "        SubhaloMassInRad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort Target Halo Catalog\n",
    "def find_total_numbers(\n",
    "        snap_number, chunk_number, \n",
    "        FilePath):\n",
    "    '''\n",
    "    Last_Halo_IDs is the number of fof halos in the sorted chunks,\n",
    "    Last_Subhalo_IDs is the number of subhalos in the sorted chunks\n",
    "    '''\n",
    "    groupcat_name = f'{FilePath}fof_subhalo_tab_0{snap_number}.{chunk_number}.hdf5'\n",
    "\n",
    "    with h5py.File(groupcat_name, 'r') as cat_hdf:\n",
    "        if not 'Group/GroupCM' in cat_hdf:\n",
    "            print(f\"Warning: {groupcat_name} is empty. Skipping data reading.\")\n",
    "            num_Halo_thiscat = 0\n",
    "            num_subhalo_thiscat = 0\n",
    "        else:\n",
    "            # Read Group Number\n",
    "            GroupNsubs = cat_hdf['Group/GroupNsubs'][:]\n",
    "            num_Halo_thiscat = GroupNsubs.shape[0]\n",
    "            # Read Subhalo Number\n",
    "            SubhaloFlag = cat_hdf['Subhalo/SubhaloFlag'][:]\n",
    "            num_subhalo_thiscat = SubhaloFlag.shape[0]\n",
    "            \n",
    "    return num_Halo_thiscat, num_subhalo_thiscat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9651b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate logging info when sorting particles\n",
    "log_file = f'{SavePath}sort_halos_0{snapnum}.log'\n",
    "os.makedirs(os.path.dirname(log_file), exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=log_file,\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "sub_prog_url = \"http://www.illustris-project.org/api/Illustris-3/snapshots/85/subhalos/185/\"\n",
    "# Get the total number of chunks. Chunk index starts from 0 \n",
    "# num_chunks = sim['num_files_snapshot']\n",
    "num_chunks = 600\n",
    "# initialize halo numbers and subhalo numbers\n",
    "num_halo = 0\n",
    "num_subhalo = 0\n",
    "for chunk_index in range(num_chunks):  # Looping over all chunks\n",
    "    print(f'sort chunk {chunk_index}')\n",
    "    \n",
    "    # Sort particles and return updated numbers\n",
    "    add_num_halo, add_num_subhalo = sort_halos(snapnum, chunk_number=chunk_index,\n",
    "                                                FilePath=FilePath, SavePath=SavePath,\n",
    "                                                Last_Halo_IDs=num_halo, Last_Subhalo_IDs=num_subhalo)\n",
    "    num_halo += add_num_halo\n",
    "    num_subhalo += add_num_subhalo\n",
    "\n",
    "    logging.info(f'Sorted {FilePath}of_subhalo_tab_0{Snap_Index}.{chunk_index}.hdf5')\n",
    "\n",
    "# Log summary\n",
    "logging.info('Sorting process completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Total Numbers\n",
    "\n",
    "# Get the total number of chunks. Chunk index starts from 0 \n",
    "# num_chunks = sim['num_files_snapshot']\n",
    "num_chunks = 600\n",
    "# initialize halo numbers and subhalo numbers\n",
    "num_halo = 0\n",
    "num_subhalo = 0\n",
    "for chunk_index in range(num_chunks):  # Looping over all chunks\n",
    "    print(f'sort chunk {chunk_index}')\n",
    "    \n",
    "    # Sort particles and return updated numbers\n",
    "    add_num_halo, add_num_subhalo = find_total_numbers(snapnum, chunk_index, \n",
    "        FilePath)\n",
    "    num_halo += add_num_halo\n",
    "    num_subhalo += add_num_subhalo\n",
    "\n",
    "print('num halo', num_halo)\n",
    "print('num subhalo', num_subhalo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb8cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetCat = f'{SavePath}TargetHalo_MergerCat_0{snapnum}.hdf5'\n",
    "with h5py.File(TargetCat, 'a') as Target_hdf:\n",
    "    Target_Halo_IDs =  Target_hdf['Group/FOF_Halo_IDs'][:]\n",
    "    Target_Subhalo_IDs = Target_hdf['Subhalo/Subhalo_IDs'][:]\n",
    "    Target_Halo_Nsubs = Target_hdf['Group/GroupNsubs'][:]\n",
    "    Target_HaloM  =  Target_hdf['Group/Group_M_Crit200'][:]\n",
    "    sub_M = Target_hdf['Subhalo/SubhaloMassInHalfRad'][:]\n",
    "    Spin = Target_hdf['Subhalo/SubhaloSpin'][:]\n",
    "    SubhaloVel = Target_hdf['Subhalo/SubhaloVel'][:]\n",
    "    SubhaloStellarPhotometrics =Target_hdf['Subhalo/SubhaloStellarPhotometrics'][:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df35755",
   "metadata": {},
   "outputs": [],
   "source": [
    "SubhaloStellarPhotometrics[800]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
