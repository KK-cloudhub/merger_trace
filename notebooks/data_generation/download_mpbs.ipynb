{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Packages\n",
    "import numpy as np\n",
    "import h5py\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# Physics-related Packages\n",
    "from astropy.cosmology import Planck15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Load Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target_cat_name = \"/users_path/merger_trace/tng_cluster/tng_cluster_targetcat/targethalo_cat_099/TargetHalo_MergerCat_099.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Constants and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparations for read box info from the url\n",
    "import requests\n",
    "\n",
    "baseUrl = 'http://www.tng-project.org/api/'\n",
    "headers = {\"api-key\":\"API KEY\"}\n",
    "\n",
    "def get(path, params=None):\n",
    "    # make HTTP GET request to path\n",
    "    r = requests.get(path, params=params, headers=headers)\n",
    "\n",
    "    # raise exception if response code is not HTTP SUCCESS (200)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    if r.headers['content-type'] == 'application/json':\n",
    "        return r.json() # parse json responses automatically\n",
    "\n",
    "    if 'content-disposition' in r.headers:\n",
    "        filename = r.headers['content-disposition'].split(\"filename=\")[1]\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        return filename # return the filename string\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Merger Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subhalo_maxM(Halo_ID, Sub_IDs, Sub_GrNr, Sub_MassType):\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds the maximum subhalo mass for a given halo.\n",
    "    \n",
    "    Parameters:\n",
    "    - Halo_ID: Array of halo IDs.\n",
    "    - Sub_GrNr: Array indicating the group number each subhalo belongs to.\n",
    "    - Sub_MassType: Array of subhalo masses.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple (Subhalo_MaxMass, Subhalo_Count): \n",
    "      - Subhalo_MaxMass: Maximum subhalo mass for each halo.\n",
    "      - Subhalo_Count: Number of subhalos for each halo.\n",
    "    \"\"\"\n",
    "        \n",
    "    find_Sub = np.where(Sub_GrNr == Halo_ID)[0]\n",
    "    find_Sub_MassType = Sub_MassType[find_Sub,:]\n",
    "    find_Sub_Mass = find_Sub_MassType[:,0] + find_Sub_MassType[:,1]\n",
    "    find_maxsubhalo_ID = Sub_IDs[find_Sub][0]\n",
    "    \n",
    "    return np.max(find_Sub_Mass), find_Sub.shape[0], find_maxsubhalo_ID\n",
    "\n",
    "def Get_HaloIDs(TargetHalo_cat):\n",
    "    \"\"\"\n",
    "    Extracts halo IDs and their properties from the HDF5 catalog.\n",
    "\n",
    "    Parameters:\n",
    "    - TargetHalo_cat: Path to the HDF5 file containing the target halo catalog.\n",
    "\n",
    "    Returns:\n",
    "    - Target_Halo_IDs: List of selected halo IDs.\n",
    "    - Subhalo_MaxMasses: Maximum subhalo masses for each selected halo.\n",
    "    - Target_Halo_Rs_Crit200: Halo critical radius R_Crit200.\n",
    "    - Target_GroupPoses: Positions of the selected halos.\n",
    "    - Galaxy_nums: Number of subhalos per halo.\n",
    "    \"\"\"\n",
    "\n",
    "    with h5py.File(TargetHalo_cat, 'a') as Target_hdf:\n",
    "        FOF_Halo_IDs =  Target_hdf['Group/FOF_Halo_IDs'][:]\n",
    "        GroupFirstSub = Target_hdf['Group/GroupFirstSub'][:]\n",
    "        GroupPos = Target_hdf['Group/GroupPos'][:]\n",
    "        Group_R_Crit200 = Target_hdf['Group/Group_R_Crit200'][:]\n",
    "        Group_M_Crit200 = Target_hdf['Group/Group_M_Crit200'][:]\n",
    "        SubhaloGrNr = Target_hdf['Subhalo/SubhaloGrNr'][:]\n",
    "        SubhaloMassType =  Target_hdf['Subhalo/SubhaloMassType'][:]\n",
    "        Sub_IDs =  Target_hdf['Subhalo/Subhalo_IDs'][:]\n",
    "\n",
    "    # Get Halo IDs and Halo Radius\n",
    "    Indices_HaloWithSub = np.where( GroupFirstSub != -1)[0]\n",
    "    Target_Halo_IDs = FOF_Halo_IDs[Indices_HaloWithSub]\n",
    "    Target_Halo_Rs_Crit200 = Group_R_Crit200[Indices_HaloWithSub]\n",
    "    Target_GroupPoses = GroupPos[Indices_HaloWithSub]\n",
    "    Target_Group_Ms_Crit200 = Group_M_Crit200 [Indices_HaloWithSub]\n",
    "\n",
    "    # Get Halo Max Subhalo Mass\n",
    "    Subhalo_MaxMasses = np.zeros(Target_Halo_IDs.shape)\n",
    "    Galaxy_nums = np.zeros(Target_Halo_IDs.shape)\n",
    "    Max_Subhalo_IDs = np.zeros(Target_Halo_IDs.shape)\n",
    "\n",
    "    for i in range(len(Target_Halo_IDs)):\n",
    "        Halo_ID = Target_Halo_IDs[i]\n",
    "        Subhalo_MaxMasses[i],  Galaxy_nums[i], Max_Subhalo_IDs[i] = get_subhalo_maxM(Halo_ID, Sub_IDs, SubhaloGrNr, SubhaloMassType)\n",
    "\n",
    "    return Target_Halo_IDs, Subhalo_MaxMasses, Target_Halo_Rs_Crit200, Target_GroupPoses, Galaxy_nums, Max_Subhalo_IDs, Target_Group_Ms_Crit200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Halo_IDs = Get_HaloIDs(Target_cat_name)[0]\n",
    "Subhalo_IDs = Get_HaloIDs(Target_cat_name)[5]\n",
    "Target_Group_Ms_Crit200 = Get_HaloIDs(Target_cat_name)[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Halo_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_with_retries(url, max_retries=5, wait_time=30):\n",
    "    \"\"\" donwload files, retry when 403 \"\"\"\n",
    "    headers =  {\"api-key\":\"API KEY\"}\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            r = requests.get(url, headers=headers, timeout=100)\n",
    "            \n",
    "            if r.status_code == 403:\n",
    "                print(f\"403 Forbidden! Waiting {wait_time} seconds before retrying ({attempt+1}/{max_retries})\")\n",
    "                time.sleep(wait_time)  # wait and retry\n",
    "                continue  \n",
    "            \n",
    "            r.raise_for_status() \n",
    "\n",
    "            if r.headers['content-type'] == 'application/json':\n",
    "                return r.json() # parse json responses automatically\n",
    "\n",
    "            if 'content-disposition' in r.headers:\n",
    "                filename = r.headers['content-disposition'].split(\"filename=\")[1]\n",
    "                with open(filename, 'wb') as f:\n",
    "                    f.write(r.content)\n",
    "                return filename # return the filename string\n",
    "            \n",
    "            return r\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"âš  Request failed: {e}. Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "    print(\"Failed after multiple retries.\")\n",
    "    return None  # if fail, return None\n",
    "\n",
    "for i in range(len(Halo_IDs)):\n",
    "    subhalo_id = int(Subhalo_IDs[i])\n",
    "    Halo_M_Crit200 = Target_Group_Ms_Crit200[i]\n",
    "    sub_mpb = f'./sublink_mpb_{subhalo_id}.hdf5'\n",
    "    \n",
    "    if os.path.exists(sub_mpb):\n",
    "        print(f\"File {sub_mpb} already exists. Skipping download.\")\n",
    "    else:\n",
    "        print(f\"File {sub_mpb} not found. Downloading from Illustris API...\")\n",
    "        mpb_url = f\"http://www.illustris-project.org/api/TNG300-1/snapshots/99/subhalos/{subhalo_id}/sublink/mpb.hdf5\"\n",
    "        \n",
    "        # get files\n",
    "        sub_mpb = get_with_retries(mpb_url)\n",
    "        \n",
    "        # time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Illustris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
