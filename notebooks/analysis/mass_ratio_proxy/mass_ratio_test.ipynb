{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd142a-b994-4c85-b37a-a2c4574abddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Packages\n",
    "import numpy as np\n",
    "import h5py\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress, pearsonr, spearmanr\n",
    "import seaborn as sns\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.stats as stats\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.patches as patches\n",
    "from skimage.feature import peak_local_max\n",
    "from matplotlib.collections import PatchCollection\n",
    "from scipy.stats import pearsonr\n",
    "from astropy.io import fits\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "# Physics-related Packages\n",
    "from astropy.cosmology import Planck15\n",
    "from astropy.wcs import WCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d921b9-c15c-4e72-9b6d-102d80138bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SN_Path = '/users_path/merger_trace/data/tng300/tng300_aperture_mass_maps'\n",
    "cat_name = '/home/chuiyang/merger_trace/data/tng300/tng300_targetcat/TargetHalo_MergerCat_092.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ffa486-c7df-45e5-8b04-d3e5be632969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparations for read box info from the url\n",
    "import requests\n",
    "\n",
    "baseUrl = 'http://www.tng-project.org/api/'\n",
    "headers = {\"api-key\":\"API KEY\"}\n",
    "\n",
    "def get(path, params=None):\n",
    "    # make HTTP GET request to path\n",
    "    r = requests.get(path, params=params, headers=headers)\n",
    "\n",
    "    # raise exception if response code is not HTTP SUCCESS (200)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    if r.headers['content-type'] == 'application/json':\n",
    "        return r.json() # parse json responses automatically\n",
    "\n",
    "    if 'content-disposition' in r.headers:\n",
    "        filename = r.headers['content-disposition'].split(\"filename=\")[1]\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        return filename # return the filename string\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4dba6-3eb0-41bb-8b08-324eaaebefcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue a request to the API root\n",
    "r = get(baseUrl)\n",
    "\n",
    "# Print out all the simulation names\n",
    "names = [sim['name'] for sim in r['simulations']]\n",
    "# Get the index of TNG300-1\n",
    "i = names.index('TNG300-1')\n",
    "# Get the info of simulation Illustris-3\n",
    "sim = get( r['simulations'][i]['url'] )\n",
    "sim.keys()\n",
    "\n",
    "# get the snaps info this simulation\n",
    "snaps = get(sim['snapshots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374cb87a-6c51-47fd-9b6a-229c3e85976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sim Box parameters\n",
    "Snap_Index = 92 # the snapshots index in the total 100 snapshots taking at different z\n",
    "BoxSize = sim['boxsize'] # unit: ckpc/h\n",
    "Redshift = snaps[Snap_Index]['redshift'] # current redshift of our current snap\n",
    "\n",
    "# Short description of cosmological parameters Planck2015\n",
    "h_atz = Planck15.H(Redshift).value/100 # unit 100km/[s*Mpc]\n",
    "\n",
    "LowerMass_lim = 5*10**3 * h_atz # units 10^ 10 ùëÄ‚äô/‚Ñé * h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c5ea93-05e6-43c5-bb9e-133cc82c21bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peaks(SN_map, min_distance, threshold_abs):\n",
    "    # Extract peak positions\n",
    "    peaks = peak_local_max(SN_map, min_distance=min_distance, threshold_abs=threshold_abs)\n",
    "    # Sort the peaks by intensity (highest to lowest)\n",
    "    peaks_sorted = np.array(sorted(peaks, key=lambda p: SN_map[p[0], p[1]], reverse=True))\n",
    "\n",
    "    return peaks_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e2eda5-cdb7-4b24-9d40-468954411a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass_ratio(cat_name, halo_id):\n",
    "    with h5py.File(cat_name) as cat:\n",
    "        Halo_IDs = cat['Group/FOF_Halo_IDs'][:]\n",
    "        GroupPos = cat['Group/GroupPos'][:]\n",
    "        Group_R_Crit200 = cat['Group/Group_R_Crit200'][:]\n",
    "        \n",
    "        SubhaloGrNr = cat['Subhalo/SubhaloGrNr'][:]\n",
    "        SubhaloMasses = cat['Subhalo/SubhaloMass'][:]\n",
    "        SubhaloPos = cat['Subhalo/SubhaloPos'][:]\n",
    "\n",
    "    halo_pos =  GroupPos[Halo_IDs == halo_id][0]\n",
    "    halo_x, halo_y, halo_z = halo_pos[0], halo_pos[1], halo_pos[2]\n",
    "    halo_r = Group_R_Crit200[Halo_IDs==halo_id]\n",
    "\n",
    "    Subhalo_in = np.where(\n",
    "        (SubhaloGrNr == halo_id) &\n",
    "        (SubhaloPos[:,0] <= halo_x + halo_r) &\n",
    "        (SubhaloPos[:,0] >= halo_x - halo_r) &\n",
    "        (SubhaloPos[:,1] <= halo_y + halo_r) &\n",
    "        (SubhaloPos[:,1] >= halo_y - halo_r) &\n",
    "        (SubhaloPos[:,2] <= halo_z + 2*halo_r) &\n",
    "        (SubhaloPos[:,2] >= halo_z - 2*halo_r) \n",
    "    )[0]\n",
    "\n",
    "    SubhaloMass_in = SubhaloMasses[Subhalo_in]\n",
    "    sorted_masses = np.sort(SubhaloMass_in)[::-1] \n",
    "\n",
    "    # get the most and second massive halos\n",
    "    if len(sorted_masses) >= 2:\n",
    "        m1, m2 = sorted_masses[0], sorted_masses[1]\n",
    "        top_sorted = np.argsort(SubhaloMass_in)[::-1]\n",
    "        top_indices = Subhalo_in[top_sorted[:2]] \n",
    "    elif len(sorted_masses) == 1:\n",
    "        m1, m2 = sorted_masses[0], 0\n",
    "        top_indices = [Subhalo_in[0]]\n",
    "    else:\n",
    "        m1, m2 = 0, 0\n",
    "        top_indices = []\n",
    "    \n",
    "    # get positions\n",
    "    top_positions = SubhaloPos[top_indices]  \n",
    "    \n",
    "    # convert to pixel pos\n",
    "    relative_xy = top_positions[:, :2] - halo_pos[:2]\n",
    "    pixel_coords = (relative_xy / (2*halo_r) * 240).astype(int) + 120  # center shift\n",
    "\n",
    "\n",
    "    return m1, m2, m2 / m1 if m1 > 0 else np.nan, pixel_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62ddaf2-d44e-4aae-a450-cce49e083d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(cat_name) as cat:\n",
    "    FOF_Halo_IDs = cat['Group/FOF_Halo_IDs'][:]\n",
    "    Group_M_Crit200 = cat['Group/Group_M_Crit200'][:]\n",
    "\n",
    "Target_Halo_IDs = FOF_Halo_IDs[Group_M_Crit200>=LowerMass_lim].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d47ae19-5c3d-419f-bee7-3a65a2b18fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_intensity_separation(halo_id, cat_name, sigma=10, min_distance=2, threshold_abs=0.05, if_plot=False):\n",
    "    # get mass ratio\n",
    "    mass1, mass2, mass_ratio, pixel_coords =get_mass_ratio(cat_name, halo_id)\n",
    "\n",
    "    # get sn_map\n",
    "    file_full = SN_Path+ f'sn_map_full_halo{halo_id}.fits'\n",
    "    file_nonoise = SN_Path +f'sn_map_nonoise_halo{halo_id}.fits'\n",
    "\n",
    "    # open fits\n",
    "    with fits.open(file_full) as hdul:\n",
    "        SN_map_full = hdul[0].data\n",
    "\n",
    "    with fits.open(file_nonoise) as hdul:\n",
    "        SN_map_nonoise = hdul[0].data\n",
    "\n",
    "    # smooth sn map with noise and find peaks\n",
    "    smoothed_SN_map = gaussian_filter(SN_map_full, sigma=sigma)\n",
    "    peaks = find_peaks(smoothed_SN_map, min_distance=min_distance, threshold_abs=threshold_abs)\n",
    "\n",
    "    if if_plot:\n",
    "        # plot smoothed sn map, and the 1st 2nd peaks\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        im0 = axs[0].imshow(smoothed_SN_map, origin='lower', cmap='viridis')\n",
    "        if len(peaks) >= 1:\n",
    "            axs[0].scatter(peaks[0][1], peaks[0][0], s=50, color='red', label='1st Peak', marker='x')\n",
    "        if len(peaks) >= 2:\n",
    "            axs[0].scatter(peaks[1][1], peaks[1][0], s=50, color='orange', label='2nd Peak', marker='x')\n",
    "\n",
    "        axs[0].set_title(f'Smoothed SN Map with Peaks (halo {halo_id})')\n",
    "        plt.colorbar(im0, ax=axs[0], fraction=0.046, pad=0.04, label='SN Value')\n",
    "\n",
    "\n",
    "        # no-noise maps and true peak positions (1st 2nd subhalos)\n",
    "        im1 = axs[1].imshow(SN_map_nonoise, origin='lower', cmap='viridis')\n",
    "        axs[1].set_title(f'Nonoise SN Map with True Subhalos (halo {halo_id})')\n",
    "        plt.colorbar(im1, ax=axs[1], fraction=0.046, pad=0.04, label='SN Value')\n",
    "        \n",
    "        if len(pixel_coords) >= 1:\n",
    "            axs[1].scatter(pixel_coords[0][1], pixel_coords[0][0],\n",
    "                           s=100, color='cyan', marker='*', label='Most Massive')\n",
    "        \n",
    "        if len(pixel_coords) == 2:\n",
    "            axs[1].scatter(pixel_coords[1][1], pixel_coords[1][0],\n",
    "                           s=100, color='magenta', marker='*', label='2nd Massive')\n",
    "        \n",
    "        axs[1].legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    if len(peaks)>1:\n",
    "        pos1 = peaks[0]\n",
    "        pos2 = peaks[1]\n",
    "        intensity_1 = smoothed_SN_map[pos1[0], pos1[1]]\n",
    "        intensity_2 = smoothed_SN_map[pos2[0], pos2[1]]\n",
    "        separation = np.linalg.norm(np.array(pos1) - np.array(pos2))\n",
    "    else:\n",
    "        intensity_1 = -1\n",
    "        intensity_2 = -1\n",
    "        separation = -1\n",
    "\n",
    "    return intensity_1, intensity_2, separation, mass_ratio\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5090e09f-252c-44d2-aa0b-0a8284ad18dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with h5py.File(cat_name) as f:\n",
    "    Group_M_Crit200 = f['Group/Group_M_Crit200'][:]\n",
    "    FOF_Halo_IDs = f['Group/FOF_Halo_IDs'][:]\n",
    "\n",
    "'''\n",
    "mass_ratios = np.zeros(len(FOF_Halo_IDs))\n",
    "for i, halo_id in enumerate(FOF_Halo_IDs):\n",
    "    m1, m2, mass_ratio, pixel_coords = get_mass_ratio(cat_name, halo_id)\n",
    "    print(mass_ratio)\n",
    "    mass_ratios[i]= mass_ratio\n",
    "    print(f'finish {i}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74499b9-7be6-4960-9011-9b2e922d544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(Target_Halo_IDs)\n",
    "intensity_1_vec = np.full(n, np.nan)\n",
    "intensity_2_vec = np.full(n, np.nan)\n",
    "separation_vec  = np.full(n, np.nan)\n",
    "true_mass_ratio_vec = np.full(n, np.nan)\n",
    "\n",
    "failed_ids = []\n",
    "\n",
    "for i, halo_id in enumerate(Target_Halo_IDs):\n",
    "    try:\n",
    "        intensity_1, intensity_2, separation, true_mass_ratio = peak_intensity_separation(\n",
    "            halo_id, cat_name, sigma=10, min_distance=2, threshold_abs=0.05, if_plot=False\n",
    "        )\n",
    "        intensity_1_vec[i] = intensity_1\n",
    "        intensity_2_vec[i] = intensity_2\n",
    "        separation_vec[i]  = separation\n",
    "        true_mass_ratio_vec[i] = true_mass_ratio\n",
    "\n",
    "        print(f'finish {halo_id}')\n",
    "    except Exception as e:\n",
    "        failed_ids.append((halo_id, str(e)))\n",
    "\n",
    "        print(f\"[skip] halo {halo_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2023896-d233-43c5-a002-6d92b36fdcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df = pd.DataFrame({\n",
    "    'intensity_1': intensity_1_vec,\n",
    "    'intensity_2': intensity_2_vec,\n",
    "    'separation': separation_vec,\n",
    "    'true_mass_ratio': true_mass_ratio_vec\n",
    "})\n",
    "\n",
    "# save to .csv\n",
    "df.to_csv('halo_peak_separation.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Illustris)",
   "language": "python",
   "name": "illustris"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
