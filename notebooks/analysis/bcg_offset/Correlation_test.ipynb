{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e946792a-2eb5-49bf-9b63-6b28ea000b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bcg_offset_x = pd.read_csv('BCG_offset_matrix_x.csv')\n",
    "bcg_offset_y = pd.read_csv('BCG_offset_matrix_y.csv')\n",
    "bcg_offset_z = pd.read_csv('BCG_offset_matrix_z.csv')\n",
    "fof_halo_to_sub84 = pd.read_csv('/users_path/merger_trace/data/tng_cluster/tng_cluster_track2snapx/fof_halo_to_sub84.csv')\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('/users_path/merger_trace/data/tng_cluster/tng_cluster_products/feats_labels_dict_tngcluster.pkl', 'rb') as f:\n",
    "    feats_labels_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b84777-5fdf-44d4-8db9-5f834b2e53a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOF_Halo_ID_At99 = np.array(fof_halo_to_sub84['FOF_Halo_ID_At99'])\n",
    "FOF_Halo_ID_At84 = np.array(fof_halo_to_sub84['FOF_Halo_ID_At84'])\n",
    "FOF_Halo_ID_bcgoffset = np.array(bcg_offset_x['FOF_Halo_ID'])\n",
    "\n",
    "sigma_3_projectx = np.array(bcg_offset_x['sigma_3_projectx'])\n",
    "sigma_5_projectx = np.array(bcg_offset_x['sigma_5_projectx'])\n",
    "sigma_10_projectx = np.array(bcg_offset_x['sigma_10_projectx'])\n",
    "sigma_0_projectx = np.array(bcg_offset_x['sigma_0_projectx'])\n",
    "\n",
    "sigma_3_projecty = np.array(bcg_offset_y['sigma_3_projecty'])\n",
    "sigma_5_projecty = np.array(bcg_offset_y['sigma_5_projecty'])\n",
    "sigma_10_projecty = np.array(bcg_offset_y['sigma_10_projecty'])\n",
    "sigma_0_projecty = np.array(bcg_offset_y['sigma_0_projecty'])\n",
    "\n",
    "sigma_3_projectz = np.array(bcg_offset_z['sigma_3_projectz'])\n",
    "sigma_5_projectz = np.array(bcg_offset_z['sigma_5_projectz'])\n",
    "sigma_10_projectz = np.array(bcg_offset_z['sigma_10_projectz'])\n",
    "sigma_0_projectz = np.array(bcg_offset_z['sigma_0_projectz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce85a54-6a23-4b24-8b6a-d8820f5c45eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "snap = 84\n",
    "merger_scores_all = np.zeros(len(FOF_Halo_ID_At99))\n",
    "merger_scores_pre = np.zeros(len(FOF_Halo_ID_At99))\n",
    "\n",
    "bcg_offsets3_x = np.zeros(len(FOF_Halo_ID_At99))\n",
    "bcg_offsets5_x = np.zeros(len(FOF_Halo_ID_At99))\n",
    "bcg_offsets10_x = np.zeros(len(FOF_Halo_ID_At99))\n",
    "bcg_offsets0_x = np.zeros(len(FOF_Halo_ID_At99))\n",
    "\n",
    "bcg_offsets3_y = np.zeros(len(FOF_Halo_ID_At99))\n",
    "bcg_offsets5_y = np.zeros(len(FOF_Halo_ID_At99))\n",
    "bcg_offsets10_y = np.zeros(len(FOF_Halo_ID_At99))\n",
    "bcg_offsets0_y = np.zeros(len(FOF_Halo_ID_At99))\n",
    "\n",
    "bcg_offsets3_z = np.zeros(len(FOF_Halo_ID_At99))\n",
    "bcg_offsets5_z = np.zeros(len(FOF_Halo_ID_At99))\n",
    "bcg_offsets10_z = np.zeros(len(FOF_Halo_ID_At99))\n",
    "bcg_offsets0_z = np.zeros(len(FOF_Halo_ID_At99))\n",
    "\n",
    "for i, halo_id in enumerate(feats_labels_dict.keys()):\n",
    "    fof_halo_at84 = FOF_Halo_ID_At84[FOF_Halo_ID_At99==halo_id]\n",
    "    \n",
    "    bcg_offset_3_x = sigma_3_projectx[FOF_Halo_ID_bcgoffset==fof_halo_at84][0]\n",
    "    bcg_offset_5_x = sigma_5_projectx[FOF_Halo_ID_bcgoffset==fof_halo_at84][0]\n",
    "    bcg_offset_10_x = sigma_10_projectx[FOF_Halo_ID_bcgoffset==fof_halo_at84][0]\n",
    "    bcg_offset_0_x = sigma_0_projectx[FOF_Halo_ID_bcgoffset==fof_halo_at84][0]\n",
    "\n",
    "    bcg_offset_3_y = sigma_3_projecty[FOF_Halo_ID_bcgoffset==fof_halo_at84][0]\n",
    "    bcg_offset_5_y = sigma_5_projecty[FOF_Halo_ID_bcgoffset==fof_halo_at84][0]\n",
    "    bcg_offset_10_y = sigma_10_projecty[FOF_Halo_ID_bcgoffset==fof_halo_at84][0]\n",
    "    bcg_offset_0_y = sigma_0_projecty[FOF_Halo_ID_bcgoffset==fof_halo_at84][0]\n",
    "\n",
    "    bcg_offset_3_z = sigma_3_projectz[FOF_Halo_ID_bcgoffset==fof_halo_at84][0]\n",
    "    bcg_offset_5_z = sigma_5_projectz[FOF_Halo_ID_bcgoffset==fof_halo_at84][0]\n",
    "    bcg_offset_10_z = sigma_10_projectz[FOF_Halo_ID_bcgoffset==fof_halo_at84][0]\n",
    "    bcg_offset_0_z = sigma_0_projectz[FOF_Halo_ID_bcgoffset==fof_halo_at84][0]\n",
    "\n",
    "    merger_score_all = feats_labels_dict[halo_id][snap]['label_score_all_tau2.0']\n",
    "    merger_score_pre = feats_labels_dict[halo_id][snap]['label_score_pre_tau2.0']\n",
    "    merger_scores_all[i] = merger_score_all\n",
    "    merger_scores_pre[i] = merger_score_pre\n",
    "    \n",
    "    bcg_offsets3_x[i] = bcg_offset_3_x\n",
    "    bcg_offsets5_x[i] = bcg_offset_5_x\n",
    "    bcg_offsets10_x[i] = bcg_offset_10_x\n",
    "    bcg_offsets0_x[i] = bcg_offset_0_x\n",
    "\n",
    "    bcg_offsets3_y[i] = bcg_offset_3_y\n",
    "    bcg_offsets5_y[i] = bcg_offset_5_y\n",
    "    bcg_offsets10_y[i] = bcg_offset_10_y\n",
    "    bcg_offsets0_y[i] = bcg_offset_0_y\n",
    "\n",
    "    bcg_offsets3_z[i] = bcg_offset_3_z\n",
    "    bcg_offsets5_z[i] = bcg_offset_5_z\n",
    "    bcg_offsets10_z[i] = bcg_offset_10_z\n",
    "    bcg_offsets0_z[i] = bcg_offset_0_z\n",
    "\n",
    "merger_scores_post = merger_scores_all - merger_scores_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc6ea88-7328-4054-b900-6ae55a7ff273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "\n",
    "def calculate_correlation(bcg_offsets, merger_scores):\n",
    "    # clean the data\n",
    "    valid = ~np.isnan(bcg_offsets) & ~np.isnan(merger_scores) & (bcg_offsets <= 500)& (bcg_offsets >= 2)\n",
    "    x = bcg_offsets[valid]\n",
    "    y = merger_scores[valid]\n",
    "\n",
    "    # Pearson & Spearman\n",
    "    r_pearson, p_pearson = pearsonr(x, y)\n",
    "    r_spearman, p_spearman = spearmanr(x, y)\n",
    "\n",
    "    # fit\n",
    "    b, m = polyfit(x, y, 1)  # y = m * x + b\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.scatter(x, y, alpha=0.6, edgecolor='k', label='Data')\n",
    "    plt.plot(x, m * x + b, color='red', label=f'Fit: y = {m:.2f}x + {b:.2f}')\n",
    "    plt.xlabel('BCG Offset')\n",
    "    plt.ylabel('Merger Score')\n",
    "    plt.title(f\"Pearson r = {r_pearson:.3f} (p = {p_pearson:.2e})\\n\"\n",
    "              f\"Spearman ρ = {r_spearman:.3f} (p = {p_spearman:.2e})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"pearson_r\": r_pearson,\n",
    "        \"pearson_p\": p_pearson,\n",
    "        \"spearman_rho\": r_spearman,\n",
    "        \"spearman_p\": p_spearman\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bac2c9-a384-499b-ba24-55bc56b3a443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quantile_binned_means(bcg_offsets, merger_scores, nq=5, quantiles= []):\n",
    "    # clean data\n",
    "    valid = ~np.isnan(bcg_offsets) & ~np.isnan(merger_scores) & (bcg_offsets<=1000)\n",
    "    x = merger_scores[valid]\n",
    "    y = bcg_offsets[valid]\n",
    "\n",
    "    print('sample_number', len(x))\n",
    "    if len(quantiles)==0:\n",
    "    # divide bins\n",
    "        quantiles = np.linspace(0, 1, nq + 1)\n",
    "        bins = np.quantile(x, quantiles)\n",
    "    else:\n",
    "        bins = np.quantile(x, quantiles)\n",
    "    bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "    mean_offsets = []\n",
    "    std_offsets = []\n",
    "    sample_num = []\n",
    "\n",
    "    for i in range(nq):\n",
    "        mask = (x >= bins[i]) & (x < bins[i + 1])\n",
    "        sample_num.append(np.sum(mask))\n",
    "        if np.sum(mask) > 0:\n",
    "            mean_offsets.append(np.mean(y[mask]))\n",
    "            std_offsets.append(np.std(y[mask]) / np.sqrt(np.sum(mask)))  # SEM\n",
    "        else:\n",
    "            mean_offsets.append(np.nan)\n",
    "            std_offsets.append(np.nan)\n",
    "    \n",
    "    bin_centers = np.array(bin_centers)\n",
    "    mean_offsets = np.array(mean_offsets)\n",
    "\n",
    "    # correlation\n",
    "    valid_corr = ~np.isnan(mean_offsets)\n",
    "    pearson_r, pearson_p = pearsonr(bin_centers[valid_corr], mean_offsets[valid_corr])\n",
    "    spearman_r, spearman_p = spearmanr(bin_centers[valid_corr], mean_offsets[valid_corr])\n",
    "    print(f\"Pearson r = {pearson_r:.3f} (p = {pearson_p:.2e})\")\n",
    "    print(f\"Spearman ρ = {spearman_r:.3f} (p = {spearman_p:.2e})\")\n",
    "    \n",
    "    # plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.errorbar(bin_centers, mean_offsets, yerr=std_offsets, fmt='o-', capsize=4)\n",
    "    plt.xlabel(\"Merger Score Quantile\")\n",
    "    plt.ylabel(\"Mean BCG Offset\")\n",
    "    plt.title(\"Quantile-binned BCG Offset vs Merger Score\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    print(len(y))\n",
    "\n",
    "\n",
    "    return bin_centers, mean_offsets, std_offsets, sample_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c587d2-a95f-4bf3-9044-4e9a312478b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def pairwise_correlations(x1, x2, x3, method='pearson'):\n",
    "    valid = ~np.isnan(x1) & ~np.isnan(x2) & ~np.isnan(x3)\n",
    "    x1, x2, x3 = x1[valid], x2[valid], x3[valid]\n",
    "\n",
    "    if method == 'pearson':\n",
    "        corr = pearsonr\n",
    "    elif method == 'spearman':\n",
    "        corr = spearmanr\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'pearson' or 'spearman'\")\n",
    "\n",
    "    r12, _ = corr(x1, x2)\n",
    "    r13, _ = corr(x1, x3)\n",
    "    r23, _ = corr(x2, x3)\n",
    "\n",
    "    return {\n",
    "        'r(x1,x2)': r12,\n",
    "        'r(x1,x3)': r13,\n",
    "        'r(x2,x3)': r23\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae13ca1e-687d-4844-97c7-277b64a4e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_pairwise_scatter(x1, x2, x3, labels=['x1', 'x2', 'x3']):\n",
    "    df = pd.DataFrame({labels[0]: x1, labels[1]: x2, labels[2]: x3}).dropna()\n",
    "\n",
    "    sns.set(style='white', font_scale=1.2)\n",
    "    g = sns.pairplot(df, kind='reg', plot_kws={'line_kws':{'color':'red'}, 'scatter_kws': {'alpha':0.5}})\n",
    "    g.fig.suptitle(\"Pairwise Correlation Plots\", y=1.02)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89e20ca-649a-4330-a802-6fc409052e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_correlations(bcg_offsets5_x, bcg_offsets5_y, bcg_offsets5_z, method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de94b14a-54c6-4dff-91d2-8e966b8426e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pairwise_scatter(bcg_offsets5_x, bcg_offsets5_y, bcg_offsets5_z,\n",
    "                      labels=['Offset_x', 'Offset_y', 'Offset_z'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7628b4be-693c-41ef-b8a9-197fcbfc054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_centers_all, mean_offsets_all, std_offsets_all, sample_num_all = plot_quantile_binned_means(bcg_offsets5_x, merger_scores_all, nq=5)\n",
    "bin_centers_pre, mean_offsets_pre, std_offsets_pre, sample_num_pre = plot_quantile_binned_means(bcg_offsets5_x, merger_scores_pre, nq=5)\n",
    "bin_centers_post, mean_offsets_post, std_offsets_post, sample_num_post = plot_quantile_binned_means(bcg_offsets5_x, merger_scores_post, nq=5, quantiles = np.array([0. , 0.3, 0.48, 0.66, 0.84, 1. ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# full merger score\n",
    "df_all = pd.DataFrame({\n",
    "    \"MergerScore_bin_center\": bin_centers_all,\n",
    "    \"Mean_BCG_Offset\": mean_offsets_all,\n",
    "    \"Std_BCG_Offset\": std_offsets_all,\n",
    "    \"Sample_Number\": sample_num_all\n",
    "})\n",
    "df_all.to_csv(\"bcg_vs_merger_score_all.csv\", index=False)\n",
    "\n",
    "# pre-merger score\n",
    "df_pre = pd.DataFrame({\n",
    "    \"MergerScore_bin_center\": bin_centers_pre,\n",
    "    \"Mean_BCG_Offset\": mean_offsets_pre,\n",
    "    \"Std_BCG_Offset\": std_offsets_pre,\n",
    "    \"Sample_Number\": sample_num_pre\n",
    "})\n",
    "df_pre.to_csv(\"bcg_vs_merger_score_pre.csv\", index=False)\n",
    "\n",
    "# post-merger score\n",
    "df_post = pd.DataFrame({\n",
    "    \"MergerScore_bin_center\": bin_centers_post,\n",
    "    \"Mean_BCG_Offset\": mean_offsets_post,\n",
    "    \"Std_BCG_Offset\": std_offsets_post,\n",
    "    \"Sample_Number\": sample_num_post\n",
    "})\n",
    "df_post.to_csv(\"bcg_vs_merger_score_post.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Illustris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
