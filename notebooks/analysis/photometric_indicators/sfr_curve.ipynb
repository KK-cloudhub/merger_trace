{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ae402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Packages\n",
    "import numpy as np\n",
    "import h5py\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "# Physics-related Packages\n",
    "from astropy.cosmology import Planck15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparations for read box info from the url\n",
    "import requests\n",
    "import time\n",
    "\n",
    "baseUrl = 'http://www.tng-project.org/api/'\n",
    "\n",
    "def get(path, params=None, max_retries=5, backoff_factor=2):\n",
    "    # make HTTP GET request to path\n",
    "    headers = {\"api-key\":\"API KEY\"}\n",
    "\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            r = requests.get(path, params=params, headers=headers)\n",
    "            r.raise_for_status()\n",
    "\n",
    "            if r.headers['content-type'] == 'application/json':\n",
    "                return r.json()\n",
    "            \n",
    "            if 'content-disposition' in r.headers:\n",
    "                filename = r.headers['content-disposition'].split(\"filename=\")[1]\n",
    "                with open(filename, 'wb') as f:\n",
    "                    f.write(r.content)\n",
    "                return filename\n",
    "            return r  # fallback\n",
    "        \n",
    "        except Exception as e:\n",
    "            attempt += 1\n",
    "            wait = backoff_factor ** attempt\n",
    "            print(f\"[Retry {attempt}/{max_retries}] Request failed: {e}. Retrying in {wait}s...\")\n",
    "            time.sleep(wait)\n",
    "\n",
    "    raise RuntimeError(f\"Failed to GET {path} after {max_retries} retries.\")\n",
    "\n",
    "# Issue a request to the API root\n",
    "r = get(baseUrl)\n",
    "\n",
    "# Print out all the simulation names\n",
    "names = [sim['name'] for sim in r['simulations']]\n",
    "# Get the index of TNG300-1\n",
    "i = names.index('TNG-Cluster')\n",
    "# Get the info of simulation Illustris-3\n",
    "sim = get( r['simulations'][i]['url'] )\n",
    "sim.keys()\n",
    "\n",
    "# get the snaps info this simulation\n",
    "snaps = get(sim['snapshots'])\n",
    "\n",
    "# Sim Box parameters\n",
    "Snap_Index = 99 # the snapshots index in the total 100 snapshots taking at different z\n",
    "BoxSize = sim['boxsize'] # unit: ckpc/h\n",
    "Redshift = snaps[Snap_Index]['redshift'] # current redshift of our current snap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436a0f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snaptime(snap):\n",
    "    snap_redshift = snaps[snap]['redshift'] \n",
    "    t_cosmic = Planck15.age(snap_redshift).value  # age of the Universe at that redshift\n",
    "    return t_cosmic\n",
    "\n",
    "snaptimes = np.array([get_snaptime(snap) for snap in range(72,100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86dfb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_time2snap(t_cosmic):\n",
    "    target = np.argmin(np.abs(snaptimes-t_cosmic))+ 72\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8cc18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sfr_range(halo_id_99, center_snap,sfr_dict, tau=0.5):\n",
    "\n",
    "    # calculate snap range based on tau\n",
    "    t_center = snaptimes[center_snap-72]\n",
    "    t_begin = t_center - tau\n",
    "    t_end = t_center + tau\n",
    "    snap_begin = max(from_time2snap(t_begin), 72)\n",
    "    #print(snap_begin)\n",
    "    snap_end = min(from_time2snap(t_end), 99)\n",
    "    #print(snap_end)\n",
    "\n",
    "\n",
    "    # extract sfr data within range\n",
    "    snap_range = sfr_dict[halo_id_99]['snaps']\n",
    "    sfrs = sfr_dict[halo_id_99]['avgsfr']\n",
    "    galnums = sfr_dict[halo_id_99]['galnum']\n",
    "\n",
    "    if np.sum(snap_range==snap_begin)==1 and np.sum(snap_range==snap_end)==1:\n",
    "        begin_idx =  np.where(snap_range==snap_begin)[0][0]\n",
    "        end_idx =  np.where(snap_range==snap_end)[0][0]\n",
    "        avg_sfr_vec = sfrs[begin_idx:end_idx+1]\n",
    "        galnum_vec = galnums[begin_idx:end_idx+1]\n",
    "        selected_snaps = snap_range[begin_idx:end_idx+1]\n",
    "\n",
    "        return avg_sfr_vec, galnum_vec, np.array(selected_snaps)\n",
    "\n",
    "\n",
    "    else:\n",
    "        return [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb6b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_fromdict(halo_id_99, center_snap, features_dict):\n",
    "\n",
    "    halo_data = features_dict[halo_id_99][center_snap]\n",
    "    if 'label_score_all_tau2.0' not in halo_data  or 'label_score_pre_tau2.0' not in halo_data:\n",
    "        return None, None  \n",
    "\n",
    "    all_merger_score = halo_data['label_score_all_tau2.0']\n",
    "\n",
    "    pre_merger_score = halo_data['label_score_pre_tau2.0']\n",
    "\n",
    "    post_merger_score = all_merger_score-pre_merger_score\n",
    "\n",
    "    return pre_merger_score, post_merger_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d4a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/users_path/merger_trace/data/tng_cluster/tng_cluster_products/sfr_tracking.pkl', 'rb') as f:\n",
    "    sfr_dict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a355890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/users_path/merger_trace/data/tng_cluster/tng_cluster_products/feats_labels_dict_tngcluster.pkl', 'rb') as f:\n",
    "    features_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec208be",
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_cut = from_time2snap(snaptimes[-1]-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424475eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_curvature_vec = []  \n",
    "curvature_vec = []\n",
    "meta_info_vec = []\n",
    "pre_merger_score_vec = []\n",
    "post_merger_score_vec = []\n",
    "\n",
    "\n",
    "for center_snap in range(72, 100):\n",
    "#for center_snap in range(72, snap_cut+1):\n",
    "    for halo_id_99 in sfr_dict.keys():\n",
    "\n",
    "        avg_sfr_vec, galnum_vec, selected_snaps = get_sfr_range(halo_id_99, center_snap, sfr_dict, tau=0.5)\n",
    "        \n",
    "        pre_merger_score, post_merger_score = get_scores_fromdict(halo_id_99, center_snap, features_dict)\n",
    "\n",
    "        snap_range = np.array(sfr_dict[halo_id_99]['snaps'])\n",
    "\n",
    "        center_snap_index = np.where(selected_snaps==center_snap)[0]\n",
    "\n",
    "        if (\n",
    "            len(selected_snaps)>=3\n",
    "            and pre_merger_score is not None \n",
    "            and post_merger_score is not None\n",
    "            and np.sum(snap_range==center_snap)==1\n",
    "            #and center_snap_index<=len(selected_snaps)*2/3\n",
    "            #and center_snap_index>=len(selected_snaps)*1/3\n",
    "        ):\n",
    "            norm_sfr_vec = avg_sfr_vec/np.mean(avg_sfr_vec)\n",
    "\n",
    "            center_sfr_norm = sfr_dict[halo_id_99]['avgsfr'][np.where((snap_range==center_snap))[0][0]]/np.mean(avg_sfr_vec)\n",
    "            begin_sfr_norm = norm_sfr_vec[0]\n",
    "            end_sfr_norm = norm_sfr_vec[-1]\n",
    "            \n",
    "            curvature_value_norm = 2*center_sfr_norm - begin_sfr_norm - end_sfr_norm\n",
    "            print(curvature_value_norm)\n",
    "\n",
    "            center_sfr = sfr_dict[halo_id_99]['avgsfr'][np.where((snap_range==center_snap))[0][0]]\n",
    "            begin_sfr = avg_sfr_vec[0]\n",
    "            end_sfr = avg_sfr_vec[-1]\n",
    "\n",
    "            curvature_value = 2*center_sfr - begin_sfr - end_sfr\n",
    "\n",
    "            norm_curvature_vec.append(curvature_value_norm)\n",
    "            curvature_vec.append(curvature_value)\n",
    "            meta_info_vec.append((halo_id_99, center_snap))\n",
    "\n",
    "            pre_merger_score_vec.append(pre_merger_score)\n",
    "            post_merger_score_vec.append(post_merger_score)\n",
    "\n",
    "        else:\n",
    "            print(f'not enough sfr values or do not find progenitor at {center_snap} for {halo_id_99}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b587de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_merger_score_vec = np.array(pre_merger_score_vec)\n",
    "norm_curvature_vec = np.array(norm_curvature_vec)\n",
    "print(len(norm_curvature_vec))\n",
    "percentiles = np.percentile(pre_merger_score_vec, [0, 20, 40, 60, 80, 100])\n",
    "print(percentiles)\n",
    "bin_centers = []\n",
    "bin_means = []\n",
    "bin_errors = []\n",
    "\n",
    "for i in range(5):\n",
    "    mask = (pre_merger_score_vec >= percentiles[i]) & (pre_merger_score_vec < percentiles[i+1])\n",
    "    values = norm_curvature_vec[mask]\n",
    "\n",
    "    if len(values) > 0:\n",
    "        bin_center = np.mean(pre_merger_score_vec[mask])\n",
    "        bin_centers.append(bin_center)\n",
    "        bin_means.append(np.mean(values))\n",
    "        bin_errors.append(np.std(values) / np.sqrt(len(values)))  # error bar: 标准误\n",
    "    else:\n",
    "        bin_centers.append(np.mean(pre_merger_score_vec[mask]))\n",
    "        bin_means.append(np.nan)\n",
    "        bin_errors.append(0)\n",
    "\n",
    "# plot\n",
    "plt.errorbar(bin_centers, bin_means, yerr=bin_errors, fmt='o', capsize=4)\n",
    "plt.xlabel('Pre-merger score (binned by quantiles)')\n",
    "plt.ylabel('Normalized curvature')\n",
    "plt.title('Normalized SFR curvature vs. Pre-merger score')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df = pd.DataFrame({\n",
    "    'bin_center': bin_centers,\n",
    "    'mean_curvature': bin_means,\n",
    "    'error_bar': bin_errors,\n",
    "    'sample_count': len(norm_curvature_vec)\n",
    "})\n",
    "\n",
    "df.to_csv('sfr_curvature_vs_pre_merger_score.csv', index=False)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ade02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "post_merger_score_vec = np.array(post_merger_score_vec)\n",
    "norm_curvature_vec = np.array(norm_curvature_vec)\n",
    "# print(len(norm_curvature_vec))\n",
    "\n",
    "score_vec = np.array(post_merger_score_vec)\n",
    "curv_vec = np.array(norm_curvature_vec)\n",
    "valid_mask = ~np.isnan(score_vec) & ~np.isnan(curv_vec)\n",
    "score_vec = score_vec[valid_mask]\n",
    "curv_vec = curv_vec[valid_mask]\n",
    "\n",
    "\n",
    "percentiles = np.percentile(score_vec, [0, 20, 40, 60, 80, 100])\n",
    "print(percentiles)\n",
    "# initialize\n",
    "bin_centers, bin_means, bin_errors, bin_counts = [], [], [], []\n",
    "\n",
    "# loop over all bins\n",
    "for i in range(5):\n",
    "    mask = (score_vec >= percentiles[i]) & (score_vec < percentiles[i+1])\n",
    "    #print(mask)\n",
    "    scores_in_bin = score_vec[mask]\n",
    "    #print(scores_in_bin)\n",
    "    curvs_in_bin = curv_vec[mask]\n",
    "\n",
    "    if len(curvs_in_bin) > 0:\n",
    "        bin_center = np.mean(scores_in_bin)\n",
    "        mean_val = np.mean(curvs_in_bin)\n",
    "        error_val = np.std(curvs_in_bin) / np.sqrt(len(curvs_in_bin))\n",
    "        count_val = len(curvs_in_bin)\n",
    "    else:\n",
    "        bin_center = (percentiles[i] + percentiles[i+1]) / 2\n",
    "        mean_val = np.nan\n",
    "        error_val = 0\n",
    "        count_val = 0\n",
    "\n",
    "    bin_centers.append(bin_center)\n",
    "    bin_means.append(mean_val)\n",
    "    bin_errors.append(error_val)\n",
    "    bin_counts.append(count_val)\n",
    "\n",
    "# save to .csv\n",
    "df = pd.DataFrame({\n",
    "    'bin_center': bin_centers,\n",
    "    'mean_curvature': bin_means,\n",
    "    'error_bar': bin_errors,\n",
    "    'sample_count': bin_counts\n",
    "})\n",
    "df.to_csv('post_merger_sfr_curvature_bins.csv', index=False)\n",
    "\n",
    "# plot\n",
    "plt.errorbar(bin_centers, bin_means, yerr=bin_errors, fmt='o', capsize=4)\n",
    "plt.xlabel('Post-merger score (binned by quantiles)')\n",
    "plt.ylabel('Normalized curvature')\n",
    "plt.title('Normalized SFR curvature vs. post-merger score')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1067a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df = pd.DataFrame({\n",
    "    'bin_center': bin_centers,\n",
    "    'mean_curvature': bin_means,\n",
    "    'error_bar': bin_errors,\n",
    "    'sample_count': len(norm_curvature_vec)\n",
    "})\n",
    "\n",
    "df.to_csv('post_merger_sfr_curvature_bins.csv', index=False)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Illustris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
